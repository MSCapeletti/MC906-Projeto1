[subs=+macros]

= Informed Search

:stem:

* Heuristics

They were a relevant parameter for our project. On Informed Search algorithms they are accounted within the path cost to serve as an evaluation that our agent will use to choose the next step it will take, the next action, and help to find a solution (sometimes optimal sometimes not) to our problem.
For the Pacman Maze problem, our heuristics worked around finding the action that would take the agent to a less distant point to the goal.
Searching on the bibliography and the internet we found two approaches taken on problems like these.

** Distância Manhattan


image::ManhattanDistanceRepr.png[manhattan, 240, 240, align=center]

Baseado na "real" distância que o agente irá percorrer. Considera o número de passos que serão dados, o número de ações que serão tomadas.

O processamento é um pouco mais custoso do que o normal, devido a essa metodologia.

----
   # Calcula a distancia entre duas posicoes, valido apenas para posicoes que fazem parte da sol
    @functools.lru_cache(maxsize=4096)
    def manhattan_distance(self, position1, position2, lim=100000):
        if position1 == position2:
            return 0

        # dicicionario com formato { item: [distancia, visitado (0 = nao, 1 = sim)], ... }
        d = dict.fromkeys(self.reachable_positions(position1), [math.inf, 0])
        d[position1] = [0, 0]

        i = 0
        while min({l[1] for l in d.values()}) == 0 and i < lim:
            m = math.inf
            current = None
            for k, v in d.items():
                if v[1] == 0 and v[0] < m:
                    current = k
                    m = v[0]

            d[current] = [m, 1]

            neighbors = self.adjacent(current)
            for neighbor in neighbors:
                if d[neighbor][1] == 0 and m + 1 < d[neighbor][0]:
                    d[neighbor] = [m + 1, 0]
                    if neighbor == position2:
                        return m + 1

            current = None
            i = i + 1

        try:
            return d[position2][0]
        except KeyError:
            return math.inf
----


O algoritmo acima checa a *distância de manhattan* entre dois pontos.
Inicialmente, ele checa se os pontos passados se referem a mesma posição, em caso positivo, já temos nossa resposta! (e nos poupa um bom processamento). Em caso negativo manhattan_distance usa uma função auxiliar (_reachable_positions_) que nos retorna um dicionário onde dada a chave (coordenadas da respectiva posição) temos um valor (uma lista [distancia, visitado]).
Enquanto não existir elementos ainda não visitados, avaliamos o *mais próximo* dentre estes,  da posição corrente da nossa busca.

Com esse nó avaliado no loop, para cada posição adjacente não avaliada, incrementa-se a distância respectiva.

Esse processo continua até que se visite a posição dada por _position2_ 

Ou seja, em resumo, simulamos os passos a serem dados para nosso agente chegar de um ponto A (_position1_) a um ponto B (_position2_) e projetamos o menor caminho possível, sustentado pela estratégia de que iniciamos cada uma das "buscas parciais" do nó com a menor distância, nos termos de manhattan, a cada iteração.


** Distância Euclidiana
    
----
      def euclidean_distance(self, position1, position2):
        if self.reachable(position1, position2) is False:
            return math.inf
        
        deltaX1 = (position2[0] - position1[0])**2
        deltaY1 = (position2[1] - position1[1])**2
        return (deltaX1 + deltaY1)**0.5
----

Essa heurística é bem mais direta em termos de lógica e processamento de dados. 

A distância euclidiana avalia simplismente, a distância em linha reta, do ponto A ao ponto B, que no caso de nosso algoritmo de busca seriam o ponto de avaliação atual ao goal.

Em primeiro lugar, checamos se os dois pontos são alcançáveis. Se sim, calculamos a distância segundo a fórmula de Euclides:

[asciimath]
++++
sqrt((x - x)² + (y - y)²)
++++

** Algoritmo

O _Greedy Best First Search Algoritm_ funciona de maneira muito parecida com o _A* Search_. A partir de um nó inicial, avalia-se o custo f(n) do caminho a cada um de seus possíveis destinos, de acordo com as ações que poderão ser tomadas.

Onde

----
f(n) = g(n) + h(n) , onde g(n) é o custo do caminho tomado e h(n) é o custo segundo a heurística adotada para a avaliação.
----

Seu nome greedy (ganancioso) se dá pelo fato de que após uma ação tomada, não faz mais parte da avaliação (até que se comprove que o caminho não se dá até o goal) os custos perantes as demais ações possíveis, os outros nós adjacentes no nosso caso.

image::Greedy.png[greedy, 240, 240, align=center]

Acima vemos uma imagem que ilustra o comportamento do algoritmo, independente de que outros nós possam formar um caminho mais caro, por agora, mas mais vantajoso como solução completa.

** Representação do estado

Como forma de facilitar nosso trabalho, usamos a estrutura da ferramenta AIMA, dada como auxílio para o desenvolvimento do nosso projeto. Aproveitamos a classe *_Node_* para armazenar o estado, que nada mais seria que as coordenadas (x, y) descrevendo a posição no maze.

Essa classe contém alguns métodos que nos serão muito úteis, como o método _path_, que nos dá o caminho percorrido até ali pela busca, ou o _expand_ que nos retorna uma lista de nós que podemos seguir a partir das ações disponíveis.

** Goal Test

Simplesmente é passado o path contendo o novo node a ser avaliado e, como estrutura do problema, nosso goal.
Caso o goal esteja contido no path achamos nosso objetivo! O agente então poderá agir.

Aqui é importante lembrar que nosso agente realiza somente buscas offline, ou seja, antes de realizar uma ação, a busca é executada e uma solução é encontrada.

** Complexidade

O algoritmo é completo, na questão que, se existente, sempre achará uma solução. Por outro lado, ele não pode ser considerado ótimo, apesar de que em alguns casos essa solução coincide com o melhor caso, justamente pelo fato de que, se posteriormente, durante a busca, o caminho se tornar custoso, mas chegarmos a uma solução, ele será apresentado ao agente.

** Comportamento Analisado



    


        






